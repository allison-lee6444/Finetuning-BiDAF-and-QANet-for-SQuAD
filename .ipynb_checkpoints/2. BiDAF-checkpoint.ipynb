{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVoMc-GrXFj3"
   },
   "source": [
    "## BiDAF (Bi-Directional Attention Flow)\n",
    "\n",
    "## Goal: Maximize the EM and F1 score to the SQuAD dataset by finetuning the existing BiDAF hyperparameter settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBSRdaZSXFj6"
   },
   "source": [
    "First, we will test learning rate and optimizer individually as they are relatively isolated from other variables but very close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use these flags to make the script portable for training\n",
    "running_in_colab=False\n",
    "running_in_local=True\n",
    "load_train_epochs=3 # how many epochs you have already trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the original batch size was 16, we were forced to decrease it to 8 due to the limited amount of computation resources. A higher batch size would cause the runtime to be out of memory, therefore making the training impossible. Moreover, a smaller batch size would also help the model to achieve a better performance when finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6ZzpLzAKQS7D"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1haUspYrXFj7"
   },
   "outputs": [],
   "source": [
    "optim_configuration=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Rj1hyvJUXFj8"
   },
   "outputs": [],
   "source": [
    "optimizer_config_list=[]\n",
    "# configuration 0, all default\n",
    "optimizer_config_list.append((\"AdaDelta\",1,\"AdaDelta_default\"))\n",
    "# configuration 1\n",
    "optimizer_config_list.append((\"Adam\",.001,\"Adam_default\"))\n",
    "# configuration 2\n",
    "optimizer_config_list.append((\"SGD\",.01,\"SGD_default\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER, LEARNING_RATE, model_name = optimizer_config_list[optim_configuration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_configuration=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_config_list=[]\n",
    "# configuration 0, all default\n",
    "lr_config_list.append((\"AdaDelta\",1,\"AdaDelta_default\"))\n",
    "# configuration 1\n",
    "lr_config_list.append((\"AdaDelta\",2,\"AdaDelta_doubled\"))\n",
    "# configuration 2\n",
    "lr_config_list.append((\"AdaDelta\",.5,\"AdaDelta_halved\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "j-4U22HtXFj9"
   },
   "outputs": [],
   "source": [
    "OPTIMIZER, LEARNING_RATE, model_name = lr_config_list[lr_configuration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jPx0RmSXFj-"
   },
   "source": [
    "Now, we have determined that AdaDelta with learning rate of 0.5 works best for this model with a F1 score of over 55 and EM score of over 67 after 3 epochs. We will then move onto batch size, which is also very much separated from other parameters.\n",
    "\n",
    "Note: model_name will be overwritten here. Please assume the optimizer and learning rate picked is the configuration with the best overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Rs7zzwqvPaR3"
   },
   "outputs": [],
   "source": [
    "dropout_rate_configuration=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iyfMRcQFE-Oq"
   },
   "outputs": [],
   "source": [
    "dropout_config_list=[]\n",
    "# configuration 0\n",
    "dropout_config_list.append((.2,model_name))\n",
    "# configuration 1\n",
    "dropout_config_list.append((0.15,\"dropout-.15\"))\n",
    "# configuration 2\n",
    "dropout_config_list.append((0.25,\"dropout-.25\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YdOtV9OaF3QO"
   },
   "outputs": [],
   "source": [
    "DROPOUT_RATE, model_name=dropout_config_list[dropout_rate_configuration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A 0.15 dropout rate actually performed better under default AdaDelta learning rate, and was thus used in the experiments of the subsequent hyperparameters. However, the final model excluded such choice as the performance of it peaked at the second epoch instead of the last epoch as expected.  Hence, we decided that making the dropout rate 0.2 would be more favorable when we train 2 more epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "styHP6ZpHKQG"
   },
   "outputs": [],
   "source": [
    "char_width_configuration=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8irwTXGsHKQH"
   },
   "outputs": [],
   "source": [
    "char_width_config_list=[]\n",
    "# configuration 0\n",
    "char_width_config_list.append((5,model_name))\n",
    "# configuration 1\n",
    "char_width_config_list.append((4,\"charwidth4\"))\n",
    "# configuration 2\n",
    "char_width_config_list.append((6,\"charwidth6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QvsNjqH6HKQH"
   },
   "outputs": [],
   "source": [
    "CHARACTER_CHANNEL_WIDTH, model_name=char_width_config_list[char_width_configuration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LL8Pe8xvHK8u"
   },
   "outputs": [],
   "source": [
    "hidden_configuration=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SyA4Huc8HK8v"
   },
   "outputs": [],
   "source": [
    "hidden_config_list=[]\n",
    "# configuration 0\n",
    "hidden_config_list.append((100,model_name))\n",
    "# configuration 1\n",
    "hidden_config_list.append((50,\"hidden50\"))\n",
    "# configuration 2\n",
    "hidden_config_list.append((200,\"hidden200\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0nsduYlkHK8v"
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE, model_name=hidden_config_list[hidden_configuration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwxVcVxtXFj-"
   },
   "source": [
    "After testing all of the configurations above, the final model was decided (the configurations above). We decided to train it to 5 epochs to observe if it was improved. The state dictionary, loss, EM, F1 of each experiment can be found under [model_name].pth inside the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4Iuuk4pXFj_",
    "outputId": "a0bdc108-51c8-47f2-81dc-ed7e2977d745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\gpans\\anaconda3\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (1.23.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gpans\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\gpans\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\gpans\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\gpans\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\gpans\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\gpans\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\gpans\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ksi8JbYgXFkA",
    "outputId": "e226928b-20d8-48aa-92f9-6d9c6898f34c"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, time\n",
    "import re, os, string, typing, gc, json\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "nlp = spacy.blank('en')\n",
    "from preprocess import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WzJf3DhXFkA"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure you have downloaded the SQuAD dataset JSON files and stored them under /data before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5o5KXZFXFkA",
    "outputId": "d32246fe-f8af-4183-dbd0-b7035a2dc3bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data:  442\n",
      "Data Keys:  dict_keys(['title', 'paragraphs'])\n",
      "Title:  University_of_Notre_Dame\n",
      "Length of data:  48\n",
      "Data Keys:  dict_keys(['title', 'paragraphs'])\n",
      "Title:  Super_Bowl_50\n",
      "--------------------------\n",
      "Train list len:  87599\n",
      "Valid list len:  34726\n"
     ]
    }
   ],
   "source": [
    "# load dataset json files\n",
    "\n",
    "train_data = load_json('./data/squad_train.json')\n",
    "valid_data = load_json('./data/squad_dev.json')\n",
    "\n",
    "# parse the json structure to return the data as a list of dictionaries\n",
    "\n",
    "train_list = parse_data(train_data)\n",
    "valid_list = parse_data(valid_data)\n",
    "print('--------------------------')\n",
    "\n",
    "print('Train list len: ',len(train_list))\n",
    "print('Valid list len: ',len(valid_list))\n",
    "\n",
    "# converting the lists into dataframes\n",
    "\n",
    "train_df = pd.DataFrame(train_list)\n",
    "valid_df = pd.DataFrame(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "R7n2FsPsXFkB",
    "outputId": "4f9f0808-755e-4b40-dc75-945807f8e7cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>[515, 541]</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>[188, 213]</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>[279, 296]</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>[381, 420]</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>[92, 126]</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question       label  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...  [515, 541]   \n",
       "1  What is in front of the Notre Dame Main Building?  [188, 213]   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...  [279, 296]   \n",
       "3                  What is the Grotto at Notre Dame?  [381, 420]   \n",
       "4  What sits on top of the Main Building at Notre...   [92, 126]   \n",
       "\n",
       "                                    answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "mP6rfz8jXFkB"
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    \n",
    "    def to_lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    df.context = df.context.apply(to_lower)\n",
    "    df.question = df.question.apply(to_lower)\n",
    "    df.answer = df.answer.apply(to_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RYTf0QB9XFkB"
   },
   "outputs": [],
   "source": [
    "preprocess_df(train_df)\n",
    "preprocess_df(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ri2CepgcXFkB",
    "outputId": "f39a5269-8e05-4433-d155-5c7df72d2cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 492 ms\n",
      "Number of sentences in dataset:  118822\n"
     ]
    }
   ],
   "source": [
    "# gather text to build vocabularies\n",
    "\n",
    "%time vocab_text = gather_text_for_vocab([train_df, valid_df])\n",
    "print(\"Number of sentences in dataset: \", len(vocab_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNIoNajFXFkB",
    "outputId": "0e1f6db7-c1aa-4861-83a6-37beb3432641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw-vocab: 96774\n",
      "vocab-length: 96776\n",
      "word2idx-length: 96776\n",
      "Wall time: 14 s\n",
      "----------------------------------\n",
      "raw-char-vocab: 1316\n",
      "char-vocab-intersect: 202\n",
      "char2idx-length: 204\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "# build word and character-level vocabularies\n",
    "\n",
    "%time word2idx, idx2word, word_vocab = build_word_vocab(vocab_text)\n",
    "print(\"----------------------------------\")\n",
    "%time char2idx, char_vocab = build_char_vocab(vocab_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngBoERTZXFkC",
    "outputId": "7b01b9f7-c2e6-4db9-ca26-2706232b9152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.2 s\n",
      "Wall time: 7.32 s\n",
      "Wall time: 2.97 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "# numericalize context and questions for training and validation set\n",
    "\n",
    "%time train_df['context_ids'] = train_df.context.apply(context_to_ids, word2idx=word2idx)\n",
    "%time valid_df['context_ids'] = valid_df.context.apply(context_to_ids, word2idx=word2idx)\n",
    "%time train_df['question_ids'] = train_df.question.apply(question_to_ids, word2idx=word2idx)\n",
    "%time valid_df['question_ids'] = valid_df.question.apply(question_to_ids, word2idx=word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdarlvXDXFkC",
    "outputId": "873e59f1-3ccb-4ac5-a718-44fc42d36d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of error indices: 921\n",
      "Number of error indices: 349\n"
     ]
    }
   ],
   "source": [
    "# get indices with tokenization errors and drop those indices \n",
    "\n",
    "train_err = get_error_indices(train_df, idx2word)\n",
    "valid_err = get_error_indices(valid_df, idx2word)\n",
    "\n",
    "train_df.drop(train_err, inplace=True)\n",
    "valid_df.drop(valid_err, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "OSVhso9eXFkC"
   },
   "outputs": [],
   "source": [
    "# get start and end positions of answers from the context\n",
    "# this is basically the label for training QA models\n",
    "\n",
    "train_label_idx = train_df.apply(index_answer, axis=1, idx2word=idx2word)\n",
    "valid_label_idx = valid_df.apply(index_answer, axis=1, idx2word=idx2word)\n",
    "\n",
    "train_df['label_idx'] = train_label_idx\n",
    "valid_df['label_idx'] = valid_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4P04dEJhXFkD"
   },
   "outputs": [],
   "source": [
    "# dump to pickle files\n",
    "\n",
    "train_df.to_pickle('bidaftrain.pkl')\n",
    "valid_df.to_pickle('bidafvalid.pkl')\n",
    "\n",
    "with open('bidafw2id.pickle','wb') as handle:\n",
    "    pickle.dump(word2idx, handle)\n",
    "\n",
    "with open('bidafc2id.pickle','wb') as handle:\n",
    "    pickle.dump(char2idx, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XGwDCpU4XFkD"
   },
   "outputs": [],
   "source": [
    "# load data from pickle files\n",
    "\n",
    "\n",
    "train_df = pd.read_pickle('bidaftrain.pkl')\n",
    "valid_df = pd.read_pickle('bidafvalid.pkl')\n",
    "\n",
    "with open('bidafw2id.pickle','rb') as handle:\n",
    "    word2idx = pickle.load(handle)\n",
    "with open('bidafc2id.pickle','rb') as handle:\n",
    "    char2idx = pickle.load(handle)\n",
    "\n",
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCyvgNQRXFkD"
   },
   "source": [
    "## Dataloader/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "sOG5DK_JXFkD"
   },
   "outputs": [],
   "source": [
    "class SquadDataset:\n",
    "    '''\n",
    "    - Creates batches dynamically by padding to the length of largest example\n",
    "      in a given batch.\n",
    "    - Calulates character vectors for contexts and question.\n",
    "    - Returns tensors for training.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, batch_size):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n",
    "        self.data = data\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def make_char_vector(self, max_sent_len, max_word_len, sentence):\n",
    "        \n",
    "        char_vec = torch.ones(max_sent_len, max_word_len).type(torch.LongTensor)\n",
    "        \n",
    "        for i, word in enumerate(nlp(sentence, disable=['parser','tagger','ner',\"lemmatizer\"])):\n",
    "            for j, ch in enumerate(word.text):\n",
    "                char_vec[i][j] = char2idx.get(ch, 0)\n",
    "        \n",
    "        return char_vec    \n",
    "    \n",
    "    def get_span(self, text):\n",
    "        \n",
    "        text = nlp(text, disable=['parser','tagger','ner'])\n",
    "        span = [(w.idx, w.idx+len(w.text)) for w in text]\n",
    "\n",
    "        return span\n",
    "\n",
    "    def __iter__(self):\n",
    "        '''\n",
    "        Creates batches of data and yields them.\n",
    "        \n",
    "        Each yield comprises of:\n",
    "        :padded_context: padded tensor of contexts for each batch \n",
    "        :padded_question: padded tensor of questions for each batch \n",
    "        :char_ctx & ques_ctx: character-level ids for context and question\n",
    "        :label: start and end index wrt context_ids\n",
    "        :context_text,answer_text: used while validation to calculate metrics\n",
    "        :ids: question_ids for evaluation\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        for batch in self.data:\n",
    "            \n",
    "            spans = []\n",
    "            ctx_text = []\n",
    "            answer_text = []\n",
    "            \n",
    "            for ctx in batch.context:\n",
    "                ctx_text.append(ctx)\n",
    "                spans.append(self.get_span(ctx))\n",
    "            \n",
    "            for ans in batch.answer:\n",
    "                answer_text.append(ans)\n",
    "                \n",
    "            \n",
    "            max_context_len = max([len(ctx) for ctx in batch.context_ids])\n",
    "            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n",
    "            \n",
    "            for i, ctx in enumerate(batch.context_ids):\n",
    "                padded_context[i, :len(ctx)] = torch.LongTensor(ctx)\n",
    "                \n",
    "            max_word_ctx = 0\n",
    "            for context in batch.context:\n",
    "                for word in nlp(context, disable=['parser','tagger','ner']):\n",
    "                    if len(word.text) > max_word_ctx:\n",
    "                        max_word_ctx = len(word.text)\n",
    "            \n",
    "            char_ctx = torch.ones(len(batch), max_context_len, max_word_ctx).type(torch.LongTensor)\n",
    "            for i, context in enumerate(batch.context):\n",
    "                char_ctx[i] = self.make_char_vector(max_context_len, max_word_ctx, context)\n",
    "            \n",
    "            max_question_len = max([len(ques) for ques in batch.question_ids])\n",
    "            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n",
    "            \n",
    "            for i, ques in enumerate(batch.question_ids):\n",
    "                padded_question[i, :len(ques)] = torch.LongTensor(ques)\n",
    "                \n",
    "            max_word_ques = 0\n",
    "            for question in batch.question:\n",
    "                for word in nlp(question, disable=['parser','tagger','ner']):\n",
    "                    if len(word.text) > max_word_ques:\n",
    "                        max_word_ques = len(word.text)\n",
    "            \n",
    "            char_ques = torch.ones(len(batch), max_question_len, max_word_ques).type(torch.LongTensor)\n",
    "            for i, question in enumerate(batch.question):\n",
    "                char_ques[i] = self.make_char_vector(max_question_len, max_word_ques, question)\n",
    "            \n",
    "            ids = list(batch.id)  \n",
    "            label = torch.LongTensor(list(batch.label_idx))\n",
    "            \n",
    "            yield (padded_context, padded_question, char_ctx, char_ques, label, ctx_text, answer_text, ids)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "15GFX63MXFkF"
   },
   "outputs": [],
   "source": [
    "train_dataset = SquadDataset(train_df, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "SgEJ4TWiXFkF"
   },
   "outputs": [],
   "source": [
    "valid_dataset = SquadDataset(valid_df, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "aCm5cEznXFkF"
   },
   "outputs": [],
   "source": [
    "a = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2NM5xbYXFkG"
   },
   "source": [
    "## BiDAF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2oDfA_mXFkG"
   },
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qyQoLShIXFkG"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOXLLsAEXFkH",
    "outputId": "a473158f-96ea-4fb7-a954-7cf5302932d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' 不是內部或外部命令、可執行的程式或批次檔。\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3jMnxFcxXFkH"
   },
   "outputs": [],
   "source": [
    "def get_glove_dict():\n",
    "    '''\n",
    "    Parses the glove word vectors text file and returns a dictionary with the words as\n",
    "    keys and their respective pretrained word vectors as values.\n",
    "\n",
    "    '''\n",
    "    encoding = 'utf-8'\n",
    "    glove_dict = {}\n",
    "    archive = zipfile.ZipFile('glove.6B.zip', 'r')\n",
    "    with archive.open(\"glove.6B.100d.txt\", \"r\") as f:\n",
    "        for line in io.TextIOWrapper(f, encoding):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            glove_dict[word] = vector\n",
    "            \n",
    "    f.close()\n",
    "    \n",
    "    return glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "D9Vw40VBXFkH"
   },
   "outputs": [],
   "source": [
    "def get_glove_dict_local_machine(): # assumes zip downloaded\n",
    "    '''\n",
    "    Parses the glove word vectors text file and returns a dictionary with the words as\n",
    "    keys and their respective pretrained word vectors as values.\n",
    "\n",
    "    '''\n",
    "    glove_dict = {}\n",
    "    with open(f\"./glove.6B.{HIDDEN_SIZE}d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            glove_dict[word] = vector\n",
    "            \n",
    "    f.close()\n",
    "    \n",
    "    return glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "BR3fvfqTXFkH"
   },
   "outputs": [],
   "source": [
    "if running_in_local:\n",
    "    glove_dict = get_glove_dict_local_machine()\n",
    "else:\n",
    "    glove_dict=get_glove_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "9A21kX-qXFkI"
   },
   "outputs": [],
   "source": [
    "def create_weights_matrix(glove_dict):\n",
    "    '''\n",
    "    Creates a weight matrix of the words that are common in the GloVe vocab and\n",
    "    the dataset's vocab. Initializes OOV words with a zero vector.\n",
    "    '''\n",
    "    weights_matrix = np.zeros((len(word_vocab), HIDDEN_SIZE))\n",
    "    words_found = 0\n",
    "    for i, word in enumerate(word_vocab):\n",
    "        try:\n",
    "            weights_matrix[i] = glove_dict[word]\n",
    "            words_found += 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return weights_matrix, words_found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1jxyNvqXFkI",
    "outputId": "892d8a4e-e4a3-43e9-f384-5edfd460b3b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words found in the GloVe vocab:  72687\n"
     ]
    }
   ],
   "source": [
    "weights_matrix, words_found = create_weights_matrix(glove_dict)\n",
    "print(\"Words found in the GloVe vocab: \" ,words_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "5rbx3XUzXFkI"
   },
   "outputs": [],
   "source": [
    "# dump the weights to load in future\n",
    "\n",
    "np.save('bidafglove_tv.npy', weights_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4rf3V-dXFkI"
   },
   "source": [
    "## Character Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qULa_r5UXFkI"
   },
   "outputs": [],
   "source": [
    "class CharacterEmbeddingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, char_vocab_dim, char_emb_dim, num_output_channels, kernel_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.char_emb_dim = char_emb_dim\n",
    "        \n",
    "        self.char_embedding = nn.Embedding(char_vocab_dim, char_emb_dim, padding_idx=1)\n",
    "        \n",
    "        self.char_convolution = nn.Conv2d(in_channels=1, out_channels=num_output_channels, kernel_size=kernel_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # x = [bs, seq_len, word_len]\n",
    "        # returns : [batch_size, seq_len, num_output_channels]\n",
    "        # the output can be thought of as another feature embedding of dim 100.\n",
    "        \n",
    "        batch_size = x.shape[0] \n",
    "        \n",
    "        x = self.dropout(self.char_embedding(x))\n",
    "        # x = [bs, seq_len, word_len, char_emb_dim]\n",
    "        \n",
    "        # following three operations manipulate x in such a way that\n",
    "        # it closely resembles an image. this format is important before \n",
    "        # we perform convolution on the character embeddings.\n",
    "        \n",
    "        x = x.permute(0,1,3,2)\n",
    "        # x = [bs, seq_len, char_emb_dim, word_len]\n",
    "        \n",
    "        x = x.view(-1, self.char_emb_dim, x.shape[3])\n",
    "        # x = [bs*seq_len, char_emb_dim, word_len]\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        # x = [bs*seq_len, 1, char_emb_dim, word_len]\n",
    "        \n",
    "        # x is now in a format that can be accepted by a conv layer. \n",
    "        # think of the tensor above in terms of an image of dimension\n",
    "        # (N, C_in, H_in, W_in).\n",
    "        \n",
    "        x = self.relu(self.char_convolution(x))\n",
    "        # x = [bs*seq_len, out_channels, H_out, W_out]\n",
    "        \n",
    "        x = x.squeeze()\n",
    "        # x = [bs*seq_len, out_channels, W_out]\n",
    "             \n",
    "        x = F.max_pool1d(x, x.shape[2]).squeeze()\n",
    "        # x = [bs*seq_len, out_channels, 1] => [bs*seq_len, out_channels]\n",
    "        \n",
    "        x = x.view(batch_size, -1, x.shape[-1])\n",
    "        # x = [bs, seq_len, out_channels]\n",
    "        # x = [bs, seq_len, features] = [bs, seq_len, 100]\n",
    "        \n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_dHCV4NXFkJ"
   },
   "source": [
    "## Highway Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "51uYJKaAXFkJ"
   },
   "outputs": [],
   "source": [
    "class HighwayNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_layers=2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.flow_layer = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n",
    "        self.gate_layer = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            \n",
    "            flow_value = F.relu(self.flow_layer[i](x))\n",
    "            gate_value = torch.sigmoid(self.gate_layer[i](x))\n",
    "            \n",
    "            x = gate_value * flow_value + (1-gate_value) * x\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjuEeTMsXFkJ"
   },
   "source": [
    "## Contextual Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "qSVQlRlZXFkJ"
   },
   "outputs": [],
   "source": [
    "class ContextualEmbeddingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.highway_net = HighwayNetwork(input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [bs, seq_len, input_dim] = [bs, seq_len, emb_dim*2]\n",
    "        # the input is the concatenation of word and characeter embeddings\n",
    "        # for the sequence.\n",
    "        \n",
    "        highway_out = self.highway_net(x)\n",
    "        # highway_out = [bs, seq_len, input_dim]\n",
    "        \n",
    "        outputs, _ = self.lstm(highway_out)\n",
    "        # outputs = [bs, seq_len, emb_dim*2]\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6e0g0WVXFkK",
    "tags": []
   },
   "source": [
    "## Attention Flow Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8pwrHBFiXFkL"
   },
   "outputs": [],
   "source": [
    "class BiDAF(nn.Module):\n",
    "    \n",
    "    def __init__(self, char_vocab_dim, emb_dim, char_emb_dim, num_output_channels, \n",
    "                 kernel_size, ctx_hidden_dim, device):\n",
    "        '''\n",
    "        char_vocab_dim = len(char2idx)\n",
    "        emb_dim = 100\n",
    "        char_emb_dim = 8\n",
    "        num_output_chanels = 100\n",
    "        kernel_size = (8,5)\n",
    "        ctx_hidden_dim = 100\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.word_embedding = self.get_glove_embedding()\n",
    "        \n",
    "        self.character_embedding = CharacterEmbeddingLayer(char_vocab_dim, char_emb_dim, \n",
    "                                                      num_output_channels, kernel_size)\n",
    "        \n",
    "        self.contextual_embedding = ContextualEmbeddingLayer(emb_dim*2, ctx_hidden_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout()\n",
    "        \n",
    "        self.similarity_weight = nn.Linear(emb_dim*6, 1, bias=False)\n",
    "        \n",
    "        self.modeling_lstm = nn.LSTM(emb_dim*8, emb_dim, bidirectional=True, num_layers=2, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        self.output_start = nn.Linear(emb_dim*10, 1, bias=False)\n",
    "        \n",
    "        self.output_end = nn.Linear(emb_dim*10, 1, bias=False)\n",
    "        \n",
    "        self.end_lstm = nn.LSTM(emb_dim*2, emb_dim, bidirectional=True, batch_first=True)\n",
    "        \n",
    "    \n",
    "    def get_glove_embedding(self):\n",
    "        \n",
    "        weights_matrix = np.load('bidafglove_tv.npy')\n",
    "        num_embeddings, embedding_dim = weights_matrix.shape\n",
    "        embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(self.device),freeze=True)\n",
    "\n",
    "        return embedding\n",
    "        \n",
    "    def forward(self, ctx, ques, char_ctx, char_ques):\n",
    "        # ctx = [bs, ctx_len]\n",
    "        # ques = [bs, ques_len]\n",
    "        # char_ctx = [bs, ctx_len, ctx_word_len]\n",
    "        # char_ques = [bs, ques_len, ques_word_len]\n",
    "        \n",
    "        ctx_len = ctx.shape[1]\n",
    "        \n",
    "        ques_len = ques.shape[1]\n",
    "        \n",
    "        ## GET WORD AND CHARACTER EMBEDDINGS\n",
    "        \n",
    "        ctx_word_embed = self.word_embedding(ctx)\n",
    "        # ctx_word_embed = [bs, ctx_len, emb_dim]\n",
    "        \n",
    "        ques_word_embed = self.word_embedding(ques)\n",
    "        # ques_word_embed = [bs, ques_len, emb_dim]\n",
    "        \n",
    "        ctx_char_embed = self.character_embedding(char_ctx)\n",
    "        # ctx_char_embed =  [bs, ctx_len, emb_dim]\n",
    "        \n",
    "        ques_char_embed = self.character_embedding(char_ques)\n",
    "        # ques_char_embed = [bs, ques_len, emb_dim]\n",
    "        \n",
    "        ## CREATE CONTEXTUAL EMBEDDING\n",
    "        \n",
    "        ctx_contextual_inp = torch.cat([ctx_word_embed, ctx_char_embed],dim=2)\n",
    "        # [bs, ctx_len, emb_dim*2]\n",
    "        \n",
    "        ques_contextual_inp = torch.cat([ques_word_embed, ques_char_embed],dim=2)\n",
    "        # [bs, ques_len, emb_dim*2]\n",
    "        \n",
    "        ctx_contextual_emb = self.contextual_embedding(ctx_contextual_inp)\n",
    "        # [bs, ctx_len, emb_dim*2]\n",
    "        \n",
    "        ques_contextual_emb = self.contextual_embedding(ques_contextual_inp)\n",
    "        # [bs, ques_len, emb_dim*2]\n",
    "        \n",
    "        \n",
    "        ## CREATE SIMILARITY MATRIX\n",
    "        \n",
    "        ctx_ = ctx_contextual_emb.unsqueeze(2).repeat(1,1,ques_len,1)\n",
    "        # [bs, ctx_len, 1, emb_dim*2] => [bs, ctx_len, ques_len, emb_dim*2]\n",
    "        \n",
    "        ques_ = ques_contextual_emb.unsqueeze(1).repeat(1,ctx_len,1,1)\n",
    "        # [bs, 1, ques_len, emb_dim*2] => [bs, ctx_len, ques_len, emb_dim*2]\n",
    "        \n",
    "        elementwise_prod = torch.mul(ctx_, ques_)\n",
    "        # [bs, ctx_len, ques_len, emb_dim*2]\n",
    "        \n",
    "        alpha = torch.cat([ctx_, ques_, elementwise_prod], dim=3)\n",
    "        # [bs, ctx_len, ques_len, emb_dim*6]\n",
    "        \n",
    "        similarity_matrix = self.similarity_weight(alpha).view(-1, ctx_len, ques_len)\n",
    "        # [bs, ctx_len, ques_len]\n",
    "        \n",
    "        \n",
    "        ## CALCULATE CONTEXT2QUERY ATTENTION\n",
    "        \n",
    "        a = F.softmax(similarity_matrix, dim=-1)\n",
    "        # [bs, ctx_len, ques_len]\n",
    "        \n",
    "        c2q = torch.bmm(a, ques_contextual_emb)\n",
    "        # [bs] ([ctx_len, ques_len] X [ques_len, emb_dim*2]) => [bs, ctx_len, emb_dim*2]\n",
    "        \n",
    "        \n",
    "        ## CALCULATE QUERY2CONTEXT ATTENTION\n",
    "        \n",
    "        b = F.softmax(torch.max(similarity_matrix,2)[0], dim=-1)\n",
    "        # [bs, ctx_len]\n",
    "        \n",
    "        b = b.unsqueeze(1)\n",
    "        # [bs, 1, ctx_len]\n",
    "        \n",
    "        q2c = torch.bmm(b, ctx_contextual_emb)\n",
    "        # [bs] ([bs, 1, ctx_len] X [bs, ctx_len, emb_dim*2]) => [bs, 1, emb_dim*2]\n",
    "        \n",
    "        q2c = q2c.repeat(1, ctx_len, 1)\n",
    "        # [bs, ctx_len, emb_dim*2]\n",
    "        \n",
    "        ## QUERY AWARE REPRESENTATION\n",
    "        \n",
    "        G = torch.cat([ctx_contextual_emb, c2q, \n",
    "                       torch.mul(ctx_contextual_emb,c2q), \n",
    "                       torch.mul(ctx_contextual_emb, q2c)], dim=2)\n",
    "        \n",
    "        # [bs, ctx_len, emb_dim*8]\n",
    "        \n",
    "        \n",
    "        ## MODELING LAYER\n",
    "        \n",
    "        M, _ = self.modeling_lstm(G)\n",
    "        # [bs, ctx_len, emb_dim*2]\n",
    "        \n",
    "        ## OUTPUT LAYER\n",
    "        \n",
    "        M2, _ = self.end_lstm(M)\n",
    "        \n",
    "        # START PREDICTION\n",
    "        \n",
    "        p1 = self.output_start(torch.cat([G,M], dim=2))\n",
    "        # [bs, ctx_len, 1]\n",
    "        \n",
    "        p1 = p1.squeeze()\n",
    "        # [bs, ctx_len]\n",
    "        \n",
    "        #p1 = F.softmax(p1, dim=-1)\n",
    "        \n",
    "        # END PREDICTION\n",
    "        \n",
    "        p2 = self.output_end(torch.cat([G, M2], dim=2)).squeeze()\n",
    "        # [bs, ctx_len, 1] => [bs, ctx_len]\n",
    "        \n",
    "        #p2 = F.softmax(p2, dim=-1)\n",
    "        \n",
    "        \n",
    "        return p1, p2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fa1RTj5AXFkM"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "3BNSWRXBXFkM"
   },
   "outputs": [],
   "source": [
    "CHAR_VOCAB_DIM = len(char2idx)\n",
    "EMB_DIM = HIDDEN_SIZE # need to match up with hidden size\n",
    "CHAR_EMB_DIM = 8\n",
    "NUM_OUTPUT_CHANNELS = HIDDEN_SIZE # need to match up with hidden size\n",
    "KERNEL_SIZE = (8,CHARACTER_CHANNEL_WIDTH)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = BiDAF(CHAR_VOCAB_DIM, \n",
    "              EMB_DIM, \n",
    "              CHAR_EMB_DIM, \n",
    "              NUM_OUTPUT_CHANNELS, \n",
    "              KERNEL_SIZE, \n",
    "              HIDDEN_SIZE, \n",
    "              device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "-e7eiLTKXFkM"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "KjzYPIoFXFkN"
   },
   "outputs": [],
   "source": [
    "if OPTIMIZER==\"AdaDelta\":\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=LEARNING_RATE)\n",
    "elif OPTIMIZER==\"Adam\":\n",
    "    optimizer=optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif OPTIMIZER==\"SGD\":\n",
    "    optimizer=optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4) # momentum added\n",
    "else:\n",
    "    raise Exception(\"Unrecognized optimizer chosen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "1m0VdUxvXFkN"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def train(model, train_dataset):\n",
    "    print(\"Starting training ........\")\n",
    "   \n",
    "    train_loss = 0.\n",
    "    batch_count = 0\n",
    "    model.train()\n",
    "    for batch in train_dataset:\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        if batch_count % 500 == 0:\n",
    "            print(f\"Starting batch: {batch_count}\")\n",
    "        batch_count += 1\n",
    "        \n",
    "        context, question, char_ctx, char_ques, label, ctx_text, ans, ids = batch\n",
    "\n",
    "        context, question, char_ctx, char_ques, label = context.to(device), question.to(device),\\\n",
    "                                   char_ctx.to(device), char_ques.to(device), label.to(device)\n",
    "\n",
    "\n",
    "        preds = model(context, question, char_ctx, char_ques)\n",
    "\n",
    "        start_pred, end_pred = preds\n",
    "\n",
    "        s_idx, e_idx = label[:,0], label[:,1]\n",
    "\n",
    "        loss = F.cross_entropy(start_pred, s_idx) + F.cross_entropy(end_pred, e_idx)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # this prevented memory overflow\n",
    "        del context, question, char_ctx, char_ques, label, ctx_text, ans, ids, preds, start_pred, end_pred,s_idx, e_idx\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss/len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "zEJCdFpJXFkN"
   },
   "outputs": [],
   "source": [
    "def valid(model, valid_dataset):\n",
    "    \n",
    "    print(\"Starting validation .........\")\n",
    "   \n",
    "    valid_loss = 0.\n",
    "\n",
    "    batch_count = 0\n",
    "    \n",
    "    f1, em = 0., 0.\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "   \n",
    "    predictions = {}\n",
    "    \n",
    "    for batch in valid_dataset:\n",
    "\n",
    "        if batch_count % 500 == 0:\n",
    "            print(f\"Starting batch {batch_count}\")\n",
    "        batch_count += 1\n",
    "\n",
    "        context, question, char_ctx, char_ques, label, ctx, answers, ids = batch\n",
    "\n",
    "        context, question, char_ctx, char_ques, label = context.to(device), question.to(device),\\\n",
    "                                   char_ctx.to(device), char_ques.to(device), label.to(device)\n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            s_idx, e_idx = label[:,0], label[:,1]\n",
    "\n",
    "            preds = model(context, question, char_ctx, char_ques)\n",
    "\n",
    "            p1, p2 = preds\n",
    "\n",
    "            \n",
    "            loss = F.cross_entropy(p1, s_idx) + F.cross_entropy(p2, e_idx)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            batch_size, c_len = p1.size()\n",
    "            ls = nn.LogSoftmax(dim=1)\n",
    "            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n",
    "            score, s_idx = score.max(dim=1)\n",
    "            score, e_idx = score.max(dim=1)\n",
    "            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n",
    "            \n",
    "           \n",
    "            for i in range(batch_size):\n",
    "                id = ids[i]\n",
    "                pred = context[i][s_idx[i]:e_idx[i]+1]\n",
    "                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n",
    "                predictions[id] = pred\n",
    "            \n",
    "\n",
    "    \n",
    "    em, f1 = evaluate(predictions)\n",
    "    return valid_loss/len(valid_dataset), em, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "NgNHepmzXFkN"
   },
   "outputs": [],
   "source": [
    "def evaluate(predictions):\n",
    "    '''\n",
    "    Gets a dictionary of predictions with question_id as key\n",
    "    and prediction as value. The validation dataset has multiple \n",
    "    answers for a single question. Hence we compare our prediction\n",
    "    with all the answers and choose the one that gives us\n",
    "    the maximum metric (em or f1). \n",
    "    This method first parses the JSON file, gets all the answers\n",
    "    for a given id and then passes the list of answers and the \n",
    "    predictions to calculate em, f1.\n",
    "    \n",
    "    \n",
    "    :param dict predictions\n",
    "    Returns\n",
    "    : exact_match: 1 if the prediction and ground truth \n",
    "      match exactly, 0 otherwise.\n",
    "    : f1_score: \n",
    "    '''\n",
    "    with open('./data/squad_dev.json','r',encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "        \n",
    "    dataset = dataset['data']\n",
    "    f1 = exact_match = total = 0\n",
    "    for article in dataset:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            for qa in paragraph['qas']:\n",
    "                total += 1\n",
    "                if qa['id'] not in predictions:\n",
    "                    continue\n",
    "                \n",
    "                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n",
    "                \n",
    "                prediction = predictions[qa['id']]\n",
    "                \n",
    "                exact_match += metric_max_over_ground_truths(\n",
    "                    exact_match_score, prediction, ground_truths)\n",
    "                \n",
    "                f1 += metric_max_over_ground_truths(\n",
    "                    f1_score, prediction, ground_truths)\n",
    "                \n",
    "    \n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "    \n",
    "    return exact_match, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "D4HzBoeOXFkO"
   },
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    '''\n",
    "    Performs a series of cleaning steps on the ground truth and \n",
    "    predicted answer.\n",
    "    '''\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    '''\n",
    "    Returns maximum value of metrics for predicition by model against\n",
    "    multiple ground truths.\n",
    "    \n",
    "    :param func metric_fn: can be 'exact_match_score' or 'f1_score'\n",
    "    :param str prediction: predicted answer span by the model\n",
    "    :param list ground_truths: list of ground truths against which\n",
    "                               metrics are calculated. Maximum values of \n",
    "                               metrics are chosen.\n",
    "                            \n",
    "    \n",
    "    '''\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "        \n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    '''\n",
    "    Returns f1 score of two strings.\n",
    "    '''\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    '''\n",
    "    Returns exact_match_score of two strings.\n",
    "    '''\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    '''\n",
    "    Helper function to record epoch time.\n",
    "    '''\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZUy6j7G_Pz9",
    "outputId": "9e501817-6f8b-45a4-8257-03ac2d7ef5b5"
   },
   "outputs": [],
   "source": [
    "if running_in_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_train_epochs:\n",
    "    checkpoint = torch.load(f\"{model_name}.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the incredibly long training time of this model (more than 3 hours using GTX 1070!), the first three epochs was trained in another environment. Therefore, we can only show the output of the last 2 epochs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "cEGSVxESXFkO",
    "outputId": "8ad76c2e-f840-4e26-e253-3ce3b37563f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Starting training ........\n",
      "Starting batch: 0\n",
      "Starting batch: 500\n",
      "Starting batch: 1000\n",
      "Starting batch: 1500\n",
      "Starting batch: 2000\n",
      "Starting batch: 2500\n",
      "Starting batch: 3000\n",
      "Starting batch: 3500\n",
      "Starting batch: 4000\n",
      "Starting batch: 4500\n",
      "Starting batch: 5000\n",
      "Starting batch: 5500\n",
      "Starting batch: 6000\n",
      "Starting batch: 6500\n",
      "Starting batch: 7000\n",
      "Starting batch: 7500\n",
      "Starting batch: 8000\n",
      "Starting batch: 8500\n",
      "Starting batch: 9000\n",
      "Starting batch: 9500\n",
      "Starting batch: 10000\n",
      "Starting batch: 10500\n",
      "Starting validation .........\n",
      "Starting batch 0\n",
      "Starting batch 500\n",
      "Starting batch 1000\n",
      "Starting batch 1500\n",
      "Starting batch 2000\n",
      "Epoch train loss : 2.507835018201583| Time: 139m 19s\n",
      "Epoch valid loss: 3.7418820450577335\n",
      "Epoch EM: 55.950804162724694\n",
      "Epoch F1: 67.76823864062513\n",
      "====================================================================================\n",
      "Epoch 5\n",
      "Starting training ........\n",
      "Starting batch: 0\n",
      "Starting batch: 500\n",
      "Starting batch: 1000\n",
      "Starting batch: 1500\n",
      "Starting batch: 2000\n",
      "Starting batch: 2500\n",
      "Starting batch: 3000\n",
      "Starting batch: 3500\n",
      "Starting batch: 4000\n",
      "Starting batch: 4500\n",
      "Starting batch: 5000\n",
      "Starting batch: 5500\n",
      "Starting batch: 6000\n",
      "Starting batch: 6500\n",
      "Starting batch: 7000\n",
      "Starting batch: 7500\n",
      "Starting batch: 8000\n",
      "Starting batch: 8500\n",
      "Starting batch: 9000\n",
      "Starting batch: 9500\n",
      "Starting batch: 10000\n",
      "Starting batch: 10500\n",
      "Starting validation .........\n",
      "Starting batch 0\n",
      "Starting batch 500\n",
      "Starting batch 1000\n",
      "Starting batch 1500\n",
      "Starting batch 2000\n",
      "Epoch train loss : 2.3018465744703662| Time: 160m 5s\n",
      "Epoch valid loss: 3.8468491832473046\n",
      "Epoch EM: 56.546830652790916\n",
      "Epoch F1: 68.57654247360973\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "ems = []\n",
    "f1s = []\n",
    "epochs = 5\n",
    "best_valid_loss=99999\n",
    "\n",
    "if running_in_colab:\n",
    "    path=f'drive/MyDrive/{model_name}.pth'\n",
    "else:\n",
    "    path=f'{model_name}.pth'\n",
    "\n",
    "for epoch in range(load_train_epochs,epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_dataset)\n",
    "    valid_loss, em, f1 = valid(model, valid_dataset)\n",
    "    \n",
    "    \n",
    "    if best_valid_loss>valid_loss: # save the best model\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': valid_loss,\n",
    "                'em':em,\n",
    "                'f1':f1,\n",
    "                }, path)\n",
    "        best_valid_loss=valid_loss\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    ems.append(em)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"Epoch valid loss: {valid_loss}\")\n",
    "    print(f\"Epoch EM: {em}\")\n",
    "    print(f\"Epoch F1: {f1}\")\n",
    "    print(\"====================================================================================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Performance of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there were no test dataset, only validation dataset was there. All the performance on the table was that after 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8atlRxvXFkO"
   },
   "outputs": [],
   "source": [
    "\n",
    "overall_result = []\n",
    "config_names=['AdaDelta_default','AdaDelta_default','AdaDelta_halved','Adam_default', 'SGD_default',\n",
    "              'dropout-.15','dropout-.25','charwidth4','hidden50']\n",
    "\n",
    "for i, _ in enumerate(config_names):\n",
    "    indiv_result = []\n",
    "    save_location =  f\"results/{config_names[i]}.pth\"\n",
    "    checkpoint = torch.load(save_location)\n",
    "    valid_loss=checkpoint['loss']\n",
    "    em=checkpoint['em']  \n",
    "    f1=checkpoint['f1']\n",
    "\n",
    "    indiv_result.append(config_names[i])\n",
    "    indiv_result.append(valid_loss)\n",
    "    indiv_result.append(em)\n",
    "    indiv_result.append(f1)\n",
    "    overall_result.append(indiv_result)\n",
    "\n",
    "print(tabulate(overall_result, headers=['Model', 'Valid Loss', 'EM', 'F1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVgPQ3w7XFkO"
   },
   "source": [
    "## References\n",
    "* Papers read/referred:\n",
    "    1. BiDAF: https://arxiv.org/abs/1611.01603\n",
    "    2. Convolutional Neural Networks for Sentence Classification: https://arxiv.org/abs/1408.5882\n",
    "    3. Highway Networks: https://arxiv.org/abs/1505.00387\n",
    "* Other helpful links:\n",
    "    1. https://nlp.seas.harvard.edu/slides/aaai16.pdf. A great resource for character embeddings. The figures in the character embedding section are taken from here.\n",
    "    2. https://towardsdatascience.com/the-definitive-guide-to-bi-directional-attention-flow-d0e96e9e666b. A great series of blogs to understand BiDAF.\n",
    "    Some of the following repos might be out of date.\n",
    "    3. https://github.com/allenai/bi-att-flow\n",
    "    4. https://github.com/galsang\n",
    "    5. https://github.com/jojonki/BiDAF/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
